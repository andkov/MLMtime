---
title: "Beginnings of modeling"
author: "Andrey Koval"
date: "Friday, January 23, 2015"
output:
  html_document:
    css: ~/GitHub/psy564/libs/css/sidebar.css
    highlight: zenburn
    theme: cerulean
    toc: yes
---

<!--  Set the working directory to the repository's base directory; this assumes the report is nested inside of only one directory.-->
```{r, echo=F, message=F} 
library(knitr)
opts_knit$set(root.dir='../../../')  #Don't combine this call with any other chunk -especially one that uses file paths.
```

<!-- Set the report-wide options, and point to the external script file. -->
```{r, echo=F, message=T}
require(knitr)
opts_chunk$set(
  results='show', 
  message = TRUE,
  comment = NA, 
  tidy = FALSE,
#   fig.height = 4.8, 
#   fig.width = 6.5, 
  out.width = NULL,
  fig.path = 'figure_rmd/',     
  dev = "png",
  dpi = 150
)
echoChunks <- FALSE
warningChunks<- FALSE
messageChunks<- FALSE
outwidthChunks <- "90%"
options(width=120) #So the output is 50% wider than the default.
read_chunk("./Chapters/03/R_Chapter3/hoffman-ch3.R") # the file to which knitr calls for the chunks
```

# Chapter 3

This report looks at the example 3a from chapter 3 of [Longitudinal Analysis: Modeling Within-Person Variation and Change](http://www.pilesofvariance.com) (Lesa Hoffman, 2014)

## Resources 

### General R

- [A GOOD PLACE TO START LEARNING R](http://www.rstudio.com/resources/training/online-learning/) - The RStudio team collects the best online resources.  

- [Swirl](http://swirlstats.com/students.html) and [DataCamp](https://www.datacamp.com/courses/introduction-to-r)  offer interactive courses.  

- for brief reviews of key books and resources see Will Beasley's [Resources Opinions](https://github.com/OuhscBbmc/RedcapExamplesAndPatterns/blob/master/DocumentationGlobal/ResourcesOpinions.md)  

 - another presentation by Will provides an excellent overview of [Statistical Collaboration with GitHub](http://htmlpreview.github.io/?https://raw.githubusercontent.com/OuhscBbmc/StatisticalComputing/master/2014_Presentations/05_May/BeasleyScugGitHub2014-05.html#/)
 - Winston Chan's [R Cookbook](http://shop.oreilly.com/product/9780596809164.do) is a perfect book to get you started with producing graphs with RStudio  
 - [Quick-R](http://www.statmethods.net/) - thorough and convenient resource for R reference  


### Modeling in R

There are several packages in R developed to fit linear and non-linear models. Some of the most popular are <code>stats</code>, <code>nlme</code>, and <code>lme4</code>. They have distinctions that we will grow to appreciate and take advantage of.
 
  - consult [Data Analysis Using Regression and Multilevel/Hierarchical Models](http://www.stat.columbia.edu/~gelman/arm/) for a nice intro to modeling 
 
#### <code>stats</code>  package  
  - [Official Documentation](http://www.rdocumentation.org/packages/stats)  
  - [lm()](http://www.rdocumentation.org/packages/stats/functions/lm) function, see [Gelman & Hill](http://www.stat.columbia.edu/~gelman/arm/), pages 38-39    
  - [glm()](http://www.rdocumentation.org/packages/stats/functions/glm) function     
  
  
  
#### <code>nlme</code>  package  
  - [Official Documentation](http://www.rdocumentation.org/packages/nlme)  
  - [gls()](http://www.rdocumentation.org/packages/nlme/functions/gls) function    
  - see a basic example of model result processing in the slides on [Statistical Modeling](http://ialsa.github.io/COAG-colloquium-2014F/2014-11-18-Statistical-Modeling.html#35) of the COAG [Colloquium series](http://ialsa.github.io/COAG-colloquium-2014F) on reproducible research.  
  

#### <code>lme4</code>  package  
  - [Official Documentation](http://www.rdocumentation.org/packages/lme4)  
  - [lmer](http://www.rdocumentation.org/packages/nlme/functions/gls) function, see [Gelman & Hill](http://www.stat.columbia.edu/~gelman/arm/), pages 259-262 
  - [lmer guide](http://htmlpreview.github.io/?https://github.com/andkov/Longitudinal_Models_of_Religiosity_NLSY97/blob/master/Vignettes/lmer/for%20Appendix/lmerGuide.html#adding-model-output)


There are many more resources on the web, but these will get you started. 

## Data input

Before we can do anything with R in RStudio, we need to load the packages we'll require for this project. Frequently we don't know which one we'll eventually end up using, so expect to edit this section as you develop the script. 
```{r LoadPackages, warning=F,message=F}

```

We would like to import data the data file

```
SAS_Chapter3a.sas7bdat
```

located at 

```
./Chapters/03/SAS_Chapter3a/
```

of your repository. 

```{r LoadData}

```



## Data inspection

We'd like to inspect the data object we've just imported. You can do it by clicking on the icon of the object in the Environment tab of RStudio. The command
```
View(ds)
```
would accomplish the same. Most of our interactions with data, however, would be with the help f question/commands we'll issue to the computer. For example, to get better idea about the object *ds*  I might ask serveral questions: what is its class? what are its dimensions? do columns have names? what do the first few rows look like? and other. This section demonstrates some of useful functions to inspect you data with. 
```{r BasicDescriptive}

```


## Wide to Long

Our data were in a wide format, with each level of the variable *occasion of measurement* recorded in a separate variable. 
```{r}
head(ch3a)
```

We'd like to rectify this, reorganizing the data entries in such a way so that the **names** of the  variables *outcome1* and *outcome2* become the **data values** of the new variable *time*.

```{r StackData}

```

## Data tweaking

We've brought the data to the structure we want (we'll work mostly with data in long/stacked format), but there are several things we can tweak about the dataset to make it easier to work with.

```{r TweakLong1}

```
The shorter the names of the objects you work with - the better. So we'll rename "ch3a" into "ds", to save on typing two extra characters. Also, it is a good idea to be using general names for datasets so that you can easier adapt the code for other projects. 


Closer inspection reveals that variables *group* is stored  stored as a numeric vector and *time* as a character vector  
```{r}
str(dsLong)

```
However, we understand that their values correspond to a particular category of response: *group* indicates *Treatment* (group=1) and *Control* (group=2), while *time* refers to *Pre-Test* (time=1) and *Post-Test* (time=2). We transform these variables into **ordered factors**, assigning the verbal descriptions (labels) to its values (labels). 


```{r TweakLong2}

```

## Graphing

To better understand the patterns we visualize the data with a simple line plot
```{r GraphingData0}

```

To make the graph more readable and informative we can resort to a variety of customizations within the *ggplot2* package, such as representing groups by different colors, customizing the scales, axes labels, as well as adding titles to each axes and the graph overall:

```{r GraphingData1}

```

In fact, there are so many possible customizations that they will clutter the script. To save on space and make script more readable, multiple graph settings can be collected in a object call *theme*

```{r LoadGraphThemes}

```

and attached to the graph as a layer

```{r GraphingData2}

```

We can also store it in a separate file and call for execution with *source()* command before attaching it to the graph
```
source("Scripts/Graphs/graphThemes.R")
```

To further disentangle the view of the pattenrs inside each group, we place individuals on separate graphs according to their group membership
```{r GraphingData3, fig.width=10}

```


## Modeling 

Now we are ready to recreate the data with statistical models. First, we'll recreate the mode from equation (3.1), also known as the "A Between-Person Empty Model".

### Run m3.1
```{r EmptyBP1}

```

As you notice, we used *gls()*  function from the *nlme* package, although *lm()* and *glm()* functions from *stats* package would also have done the trick, with some ideosyncrasies. These function construct model objects ( in which model outcomes are stored ) differently and retrieving information from them becomes a hassle. To standardize the experience with a greater number of models, we'll use *gls()* and not a simpler *lm()* to estimate models without random components. 
  
```{r EmptyBP2}

```

Now our dataset contains both observed data (outcome) and data predicted by model 3.1 (m3.1).
```{r EmptyBP3}

```

### Graph m3.1
To better appreciate the implications of this statistical model, let us graph the prediction that this model made FOR EACH INDIVIDUAL. We can re-use the graph from before, only map it do different data
```{r EmptyBP4, fig.width=10}

```

All groups and occassions recieve identical prediction: the grand mean. 

The syntax of ggplot2 allows us building graphs layer by layer. Let us combine observed values (colored lines) and predicted values (black lines) on the same graph. We accomplish this by taking advantage of the plot- and geom- specific mapping of data

```{r EmptyBP5, fig.width=10}

```


### Run m3.2
Similarly, we can fit "A Within-Person Empty Model"
```{r EmptyWP1}

```

Notice that we use a different function, *lmer()* of the *lme4* package. Its model object is slightly different so we have to process it differently:

```{r EmptyWP2}

```

### Graph m3.2


```{r EmptyWP3}

```


```{r EmptyWP4, fig.width=10}

```

```{r EmptyWP5, fig.width=10}

```






























